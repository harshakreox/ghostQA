"""
AI Test Case Generation - Backend with Ollama Support
Supports both Anthropic Claude and Ollama (local LLMs)
"""

from pydantic import BaseModel
from typing import List, Optional
from models import TestCase, TestAction
import os
import json
import re
import requests


class GenerateTestCasesRequest(BaseModel):
    """Request to generate test cases from BRD"""
    brd_content: str
    project_id: Optional[str] = None
    project_context: Optional[str] = None
    base_url: Optional[str] = None


class GeneratedTestCase(BaseModel):
    """A test case generated by AI"""
    name: str
    description: str
    actions: List[TestAction]
    confidence_score: float = 0.0
    notes: Optional[str] = None


class GenerateTestCasesResponse(BaseModel):
    """Response containing generated test cases"""
    test_cases: List[GeneratedTestCase]
    total_generated: int
    brd_summary: str
    suggestions: List[str] = []


class OllamaTestCaseGenerator:
    """Service for generating test cases using Ollama (local LLM)"""
    
    def __init__(self, model: str = "llama3.1", base_url: str = "http://localhost:11434"):
        """
        Initialize Ollama generator
        
        Args:
            model: Ollama model name (llama3.1, mistral, codellama, etc.)
            base_url: Ollama API base URL
        """
        self.model = model
        self.base_url = base_url
        self.api_url = f"{base_url}/api/generate"
        
        # Verify Ollama is running
        try:
            response = requests.get(f"{base_url}/api/tags", timeout=2)
            if response.status_code != 200:
                raise ConnectionError("Ollama is not responding")
            
            # Check if model exists
            models = response.json().get('models', [])
            model_names = [m['name'].split(':')[0] for m in models]
            
            if not any(self.model in name for name in model_names):
                print(f"âš ï¸ Warning: Model '{self.model}' not found. Available models: {model_names}")
                print(f"Install with: ollama pull {self.model}")
                
        except requests.exceptions.RequestException:
            raise ConnectionError(
                "Cannot connect to Ollama. Make sure Ollama is running.\n"
                "Start with: ollama serve"
            )
    
    def generate_test_cases(
        self,
        brd_content: str,
        project_context: Optional[str] = None,
        base_url: Optional[str] = None
    ) -> GenerateTestCasesResponse:
        """Generate test cases from BRD using Ollama"""
        
        # Build the prompt
        prompt = self._build_prompt(brd_content, project_context, base_url)
        
        # Call Ollama API
        ai_response = self._call_ollama_api(prompt)
        
        # Parse response into test cases
        test_cases = self._parse_ai_response(ai_response)
        
        # Extract summary and suggestions
        brd_summary = self._extract_summary(ai_response)
        suggestions = self._extract_suggestions(ai_response)
        
        return GenerateTestCasesResponse(
            test_cases=test_cases,
            total_generated=len(test_cases),
            brd_summary=brd_summary,
            suggestions=suggestions
        )
    
    def _build_prompt(
        self,
        brd_content: str,
        project_context: Optional[str] = None,
        base_url: Optional[str] = None
    ) -> str:
        """Build comprehensive prompt for LLM"""
        
        prompt = f"""You are an expert QA automation engineer. Analyze this Business Requirements Document (BRD) and generate comprehensive, automated test cases.

# BRD Content:
{brd_content}

{f"# Project Context: {project_context}" if project_context else ""}
{f"# Application Base URL: {base_url}" if base_url else ""}

# Your Task:
Generate detailed test cases that cover the requirements in the BRD. Each test case should be executable as an automated UI test.

# Available Action Types:
1. navigate - Navigate to a URL
2. click - Click an element
3. type - Type text into an input field
4. select - Select from dropdown
5. assert_visible - Assert element is visible
6. assert_text - Assert element contains specific text
7. assert_value - Assert input has specific value
8. wait - Wait for element or time

# Output Format (CRITICAL - MUST BE VALID JSON):
{{
  "summary": "Brief summary of what you understood from the BRD",
  "test_cases": [
    {{
      "name": "Test Case Name",
      "description": "What this test validates",
      "confidence_score": 0.95,
      "notes": "Any assumptions made",
      "actions": [
        {{
          "type": "navigate",
          "url": "https://example.com/login",
          "description": "Navigate to login page",
          "selector": "",
          "value": ""
        }},
        {{
          "type": "type",
          "selector": "username",
          "value": "test_user",
          "description": "Enter username",
          "url": ""
        }},
        {{
          "type": "click",
          "selector": "login-button",
          "description": "Click login button",
          "url": "",
          "value": ""
        }},
        {{
          "type": "assert_visible",
          "selector": "dashboard",
          "description": "Verify dashboard is visible",
          "url": "",
          "value": ""
        }}
      ]
    }}
  ],
  "suggestions": [
    "Test additional scenarios like password reset",
    "Consider edge cases like special characters"
  ]
}}

# Important Guidelines:
1. Generate 5-10 test cases (focus on quality over quantity)
2. Cover happy paths, negative scenarios, and edge cases
3. Use descriptive test names
4. Include assertions to validate behavior
5. Use simple CSS selectors (IDs, classes)
6. Confidence score: 0.0 to 1.0
7. Each action MUST have all 5 fields: type, selector, value, url, description

# CRITICAL REQUIREMENTS:
- Return ONLY valid JSON (no markdown, no explanations)
- All strings must be properly escaped
- Every action must have type, selector, value, url, description fields
- Even if empty, include the field as empty string ""

Generate the test cases now (JSON only):"""

        return prompt
    
    def _call_ollama_api(self, prompt: str) -> str:
        """Call Ollama API and return response"""
        
        try:
            payload = {
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9,
                }
            }
            
            print(f"ðŸ¦™ Calling Ollama with model: {self.model}...")
            
            response = requests.post(
                self.api_url,
                json=payload,
                timeout=120  # 2 minutes timeout
            )
            
            if response.status_code != 200:
                raise Exception(f"Ollama API error: {response.status_code} - {response.text}")
            
            data = response.json()
            ai_response = data.get('response', '')
            
            print(f"âœ… Ollama response received ({len(ai_response)} chars)")
            
            return ai_response
            
        except requests.exceptions.Timeout:
            raise Exception("Ollama request timed out. Try a smaller BRD or increase timeout.")
        except requests.exceptions.RequestException as e:
            raise Exception(f"Error calling Ollama API: {str(e)}")
    
    def _parse_ai_response(self, ai_response: str) -> List[GeneratedTestCase]:
        """Parse AI response into test cases"""
        
        try:
            # Clean up response (remove markdown code blocks if present)
            cleaned = ai_response.strip()
            
            # Remove markdown code blocks
            if '```json' in cleaned:
                cleaned = cleaned.split('```json')[1].split('```')[0]
            elif '```' in cleaned:
                cleaned = cleaned.split('```')[1].split('```')[0]
            
            cleaned = cleaned.strip()
            
            # Try to extract JSON if there's extra text
            if not cleaned.startswith('{'):
                # Find first { and last }
                start = cleaned.find('{')
                end = cleaned.rfind('}') + 1
                if start != -1 and end > start:
                    cleaned = cleaned[start:end]
            
            # Parse JSON
            data = json.loads(cleaned)
            
            # Convert to GeneratedTestCase objects
            test_cases = []
            for tc in data.get("test_cases", []):
                # Convert actions
                actions = []
                for action_data in tc.get("actions", []):
                    action = TestAction(
                        type=action_data.get("type", ""),
                        selector=action_data.get("selector", ""),
                        value=action_data.get("value", ""),
                        url=action_data.get("url", ""),
                        description=action_data.get("description", "")
                    )
                    actions.append(action)
                
                test_case = GeneratedTestCase(
                    name=tc.get("name", "Untitled Test"),
                    description=tc.get("description", ""),
                    actions=actions,
                    confidence_score=float(tc.get("confidence_score", 0.8)),
                    notes=tc.get("notes", "")
                )
                test_cases.append(test_case)
            
            return test_cases
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON Parse Error: {str(e)}")
            print(f"Response preview: {ai_response[:500]}")
            raise Exception(
                f"Failed to parse AI response as JSON. "
                f"The model may have returned invalid JSON. "
                f"Try using a different model or adjusting the BRD. "
                f"Error: {str(e)}"
            )
        except Exception as e:
            raise Exception(f"Error parsing AI response: {str(e)}")
    
    def _extract_summary(self, ai_response: str) -> str:
        """Extract BRD summary from AI response"""
        try:
            cleaned = ai_response.strip()
            if '```json' in cleaned:
                cleaned = cleaned.split('```json')[1].split('```')[0]
            elif '```' in cleaned:
                cleaned = cleaned.split('```')[1].split('```')[0]
            cleaned = cleaned.strip()
            
            if not cleaned.startswith('{'):
                start = cleaned.find('{')
                end = cleaned.rfind('}') + 1
                if start != -1 and end > start:
                    cleaned = cleaned[start:end]
            
            data = json.loads(cleaned)
            return data.get("summary", "BRD analysis completed.")
        except:
            return "BRD analysis completed."
    
    def _extract_suggestions(self, ai_response: str) -> List[str]:
        """Extract testing suggestions from AI response"""
        try:
            cleaned = ai_response.strip()
            if '```json' in cleaned:
                cleaned = cleaned.split('```json')[1].split('```')[0]
            elif '```' in cleaned:
                cleaned = cleaned.split('```')[1].split('```')[0]
            cleaned = cleaned.strip()
            
            if not cleaned.startswith('{'):
                start = cleaned.find('{')
                end = cleaned.rfind('}') + 1
                if start != -1 and end > start:
                    cleaned = cleaned[start:end]
            
            data = json.loads(cleaned)
            return data.get("suggestions", [])
        except:
            return []


class AnthropicTestCaseGenerator:
    """Service for generating test cases using Anthropic Claude API"""
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("ANTHROPIC_API_KEY")
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY not found")
    
    def generate_test_cases(
        self,
        brd_content: str,
        project_context: Optional[str] = None,
        base_url: Optional[str] = None
    ) -> GenerateTestCasesResponse:
        """Generate test cases from BRD using Claude AI"""
        
        # Build the prompt (same as Ollama)
        generator = OllamaTestCaseGenerator()
        prompt = generator._build_prompt(brd_content, project_context, base_url)
        
        # Call Claude API
        ai_response = self._call_claude_api(prompt)
        
        # Parse response (same parsing logic)
        test_cases = generator._parse_ai_response(ai_response)
        brd_summary = generator._extract_summary(ai_response)
        suggestions = generator._extract_suggestions(ai_response)
        
        return GenerateTestCasesResponse(
            test_cases=test_cases,
            total_generated=len(test_cases),
            brd_summary=brd_summary,
            suggestions=suggestions
        )
    
    def _call_claude_api(self, prompt: str) -> str:
        """Call Claude API and return response"""
        
        try:
            import anthropic
            
            client = anthropic.Anthropic(api_key=self.api_key)
            
            message = client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=8000,
                messages=[{"role": "user", "content": prompt}]
            )
            
            return message.content[0].text
            
        except Exception as e:
            raise Exception(f"Error calling Claude API: {str(e)}")


# Factory function to get appropriate generator
def get_test_case_generator():
    """
    Get the appropriate test case generator based on configuration.
    Priority: Ollama (local) > Anthropic (API)
    """
    
    # Check if Ollama is available
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=2)
        if response.status_code == 200:
            # Get model from env or use default
            model = os.getenv("OLLAMA_MODEL", "tinyllama:1.1b")
            print(f"âœ… Using Ollama with model: {model}")
            return OllamaTestCaseGenerator(model=model)
    except:
        pass
    
    # Fall back to Anthropic
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if api_key:
        print("âœ… Using Anthropic Claude API")
        return AnthropicTestCaseGenerator(api_key=api_key)
    
    # Neither available
    raise ValueError(
        "No AI service available. Please either:\n"
        "1. Install and start Ollama: https://ollama.ai\n"
        "2. Set ANTHROPIC_API_KEY environment variable"
    )


# File extraction utilities (same as before)

def extract_text_from_txt(file_path: str) -> str:
    """Extract text from TXT file"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except:
        with open(file_path, 'r', encoding='latin-1') as f:
            return f.read()


def extract_text_from_docx(file_path: str) -> str:
    """Extract text from DOCX file"""
    try:
        from docx import Document
        doc = Document(file_path)
        text = []
        for paragraph in doc.paragraphs:
            text.append(paragraph.text)
        return '\n'.join(text)
    except ImportError:
        raise Exception("python-docx not installed. Install with: pip install python-docx")
    except Exception as e:
        raise Exception(f"Error reading DOCX file: {str(e)}")


def extract_text_from_pdf(file_path: str) -> str:
    """Extract text from PDF file"""
    try:
        import pdfplumber
        text = []
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                text.append(page.extract_text())
        return '\n'.join(text)
    except ImportError:
        raise Exception("pdfplumber not installed. Install with: pip install pdfplumber")
    except Exception as e:
        raise Exception(f"Error reading PDF file: {str(e)}")


def extract_text_from_file(file_path: str) -> str:
    """Extract text from file based on extension"""
    
    ext = os.path.splitext(file_path)[1].lower()
    
    if ext == '.txt':
        return extract_text_from_txt(file_path)
    elif ext == '.docx':
        return extract_text_from_docx(file_path)
    elif ext == '.pdf':
        return extract_text_from_pdf(file_path)
    else:
        raise Exception(f"Unsupported file format: {ext}. Supported: .txt, .docx, .pdf")